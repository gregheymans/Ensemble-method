{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODNet on the experimental, HSE and PBE datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we will see if training first the MODNet model on the PBE, HSE and experimental datasets and then, fine tuning the model on the experimental dataset will improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T14:40:23.266058Z",
     "start_time": "2021-02-05T14:40:14.788863Z"
    }
   },
   "outputs": [],
   "source": [
    "from modnet.preprocessing import MODData\n",
    "from modnet.models import MODNetModel\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T14:40:23.277271Z",
     "start_time": "2021-02-05T14:40:23.268098Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from modnet.preprocessing import MODData\n",
    "\n",
    "def shuffle_MD(data,random_state=10):\n",
    "    data = copy.deepcopy(data)\n",
    "    ids = data.df_targets.sample(frac=1,random_state=random_state).index\n",
    "    data.df_featurized = data.df_featurized.loc[ids]\n",
    "    data.df_targets = data.df_targets.loc[ids]\n",
    "    data.df_structure = data.df_structure.loc[ids]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def MDKsplit(data,n_splits=5,random_state=10):\n",
    "    data = shuffle_MD(data,random_state=random_state)\n",
    "    ids = np.array(data.structure_ids)\n",
    "    kf = KFold(n_splits=n_splits,shuffle=True,random_state=random_state)\n",
    "    folds = []\n",
    "    for train_idx, val_idx in kf.split(ids):\n",
    "        data_train = MODData(data.df_structure.iloc[train_idx]['structure'].values,data.df_targets.iloc[train_idx].values,target_names=data.df_targets.columns,structure_ids=ids[train_idx])\n",
    "        data_train.df_featurized = data.df_featurized.iloc[train_idx]\n",
    "        #data_train.optimal_features = data.optimal_features\n",
    "        \n",
    "        data_val = MODData(data.df_structure.iloc[val_idx]['structure'].values,data.df_targets.iloc[val_idx].values,target_names=data.df_targets.columns,structure_ids=ids[val_idx])\n",
    "        data_val.df_featurized = data.df_featurized.iloc[val_idx]\n",
    "        #data_val.optimal_features = data.optimal_features\n",
    "\n",
    "        folds.append((data_train,data_val))\n",
    "        \n",
    "    return folds\n",
    "\n",
    "def MD_append(md,lmd):\n",
    "    md = copy.deepcopy(md)\n",
    "    for m in lmd:\n",
    "        md.df_structure.append(m.df_structure)\n",
    "        md.df_targets.append(m.df_targets)\n",
    "        md.df_featurized.append(m.df_featurized)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T14:40:42.270039Z",
     "start_time": "2021-02-05T14:40:23.279654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you use the ChemEnv tool for your research, please consider citing the following reference(s) :\n",
      "==================================================================================================\n",
      "David Waroquiers, Xavier Gonze, Gian-Marco Rignanese, Cathrin Welker-Nieuwoudt, Frank Rosowski,\n",
      "Michael Goebel, Stephan Schenk, Peter Degelmann, Rute Andre, Robert Glaum, and Geoffroy Hautier,\n",
      "\"Statistical analysis of coordination environments in oxides\",\n",
      "Chem. Mater., 2017, 29 (19), pp 8346-8360,\n",
      "DOI: 10.1021/acs.chemmater.7b02766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f631495c610> object, created with modnet version <=0.1.7\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f6314962970> object, created with modnet version <=0.1.7\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f628d2fa490> object, created with modnet version 0.1.8~develop\n"
     ]
    }
   ],
   "source": [
    "md_exp = MODData.load('exp_gap_all')\n",
    "md_exp.df_targets.columns = ['gap']\n",
    "md_pbe = MODData.load('pbe_gap.zip')\n",
    "md_pbe.df_targets.columns = ['gap']\n",
    "md_hse = MODData.load('hse_gap.zip')\n",
    "md_hse.df_targets.columns = ['gap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T18:15:25.027009Z",
     "start_time": "2021-02-05T17:22:05.832582Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f61eaae0190> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.359\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.369\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 1.081\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.323\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.352\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.333\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.315\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.344\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.355\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.346\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.337\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.336\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.375\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.307\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.329\n",
      "INFO:root:Preset #15 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_ph1\n",
      "0.4132849590166959\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "mae\n",
      "0.4229509172268944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f61cc8fb1f0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.360\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.383\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.359\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.390\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.346\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.374\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.352\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.347\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.389\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.299\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.331\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.390\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.400\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.345\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.363\n",
      "INFO:root:Preset #11 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_ph1\n",
      "0.35829314908498844\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "mae\n",
      "0.33912509566118193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f61ccbdae50> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.424\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.414\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.358\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.395\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.398\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.412\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.344\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.392\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.409\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.416\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.340\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.389\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.399\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.361\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.367\n",
      "INFO:root:Preset #12 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_ph1\n",
      "0.4690442903929911\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "mae\n",
      "0.45525874754995055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f61f58178b0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.395\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.429\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.438\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.385\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.387\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.380\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.377\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.365\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.376\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.386\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.348\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.378\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.393\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.361\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.343\n",
      "INFO:root:Preset #16 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_ph1\n",
      "0.4107633841241524\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "mae\n",
      "0.3987802996246108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f61bc46cd00> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.417\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.506\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.396\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.411\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.438\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.459\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.402\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.419\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.420\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.429\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.402\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.411\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.433\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.404\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.405\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.407\n",
      "INFO:root:Preset #3 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_ph1\n",
      "0.3930739010602724\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "mae\n",
      "1.1986566424816412\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "random_state = 202010\n",
    "folds = MDKsplit(md_exp,n_splits=k,random_state=random_state)\n",
    "maes_ph1 = np.ones(5)\n",
    "maes_ph2 = np.ones(5)\n",
    "maes = np.ones(5)\n",
    "for i,f in enumerate(folds):\n",
    "    train = f[0]\n",
    "    test = f[1]\n",
    "    fpath = 'train_{}_{}'.format(random_state,i+1)\n",
    "    if os.path.exists(fpath):\n",
    "        train = MODData.load(fpath)\n",
    "        train.df_targets.columns=['gap']\n",
    "    else:\n",
    "        train.feature_selection(n=-1)\n",
    "        train.save(fpath)\n",
    "        \n",
    "    # assure no overlap\n",
    "    assert len(set(train.df_targets.index).intersection(set(test.df_targets.index))) == 0\n",
    "    \n",
    "    #phase 1\n",
    "    md = MD_append(train,[md_pbe,md_hse])\n",
    "    \n",
    "    model = MODNetModel([[['gap']]],{'gap':1})\n",
    "    model.fit_preset(md,verbose=0)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    true = test.df_targets\n",
    "    error = pred-true\n",
    "    error = error.drop(pred.index[((pred['gap']).abs()>20)]) # drop unrealistic values: happens extremely rarely\n",
    "    mae = np.abs(error.values).mean()\n",
    "    print('mae_ph1')\n",
    "    print(mae)\n",
    "    maes_ph1[i] = mae\n",
    "    \n",
    "        # phase2\n",
    "    rlr = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=20, verbose=1, mode=\"auto\", min_delta=0)\n",
    "    es = EarlyStopping(monitor=\"loss\", min_delta=0.001, patience=300, verbose=1, mode=\"auto\", baseline=None,restore_best_weights=True)\n",
    "    model.fit(train,lr=0.01, epochs = 250, batch_size = 32, loss='mae', callbacks=[rlr,es], verbose=0)\n",
    "    model.fit(train,lr=0.01, epochs = 250, batch_size = 64, loss='mae', callbacks=[rlr,es], verbose=0)\n",
    "    model.fit(train,lr=0.01, epochs = 250, batch_size = 128, loss='mae', callbacks=[rlr,es], verbose=0)\n",
    "    model.fit(train,lr=0.01, epochs = 250, batch_size = 256, loss='mae', callbacks=[rlr,es], verbose=0)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    true = test.df_targets\n",
    "    error = pred-true\n",
    "    error = error.drop(pred.index[((pred['gap']).abs()>20)]) # drop unrealistic values: happens extremely rarely\n",
    "    mae = np.abs(error.values).mean()\n",
    "    print('mae')\n",
    "    print(mae)\n",
    "    maes[i] = mae \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T18:15:25.033343Z",
     "start_time": "2021-02-05T18:15:25.029067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40889193673582014"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maes_ph1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T18:15:25.038705Z",
     "start_time": "2021-02-05T18:15:25.035091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629543405088558"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modnet]",
   "language": "python",
   "name": "conda-env-modnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
