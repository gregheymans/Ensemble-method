{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODNet on the joined PBE and experimental datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we joined the PBE and experimental datasets, and trained the MODNet model on it. We weighted the data from the experimental dataset a bit more such that: {'pbe_gap':0.3, 'exp_gap':0.7}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T15:45:40.686332Z",
     "start_time": "2021-02-03T15:45:34.478170Z"
    }
   },
   "outputs": [],
   "source": [
    "from modnet.preprocessing import MODData\n",
    "from modnet.models import MODNetModel\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T15:19:36.190230Z",
     "start_time": "2021-02-03T15:19:36.153345Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from modnet.preprocessing import MODData\n",
    "from modnet.model_presets import *\n",
    "\n",
    "class MODNetModel:\n",
    "    \n",
    "    def __init__(self,targets,weights,num_neurons=[[64],[32],[16],[16]], n_feat=300,act='relu',out_act='linear'):\n",
    "\n",
    "        self.targets = targets\n",
    "        self.n_feat = n_feat\n",
    "        self.weights = weights\n",
    "        self.out_act = out_act\n",
    "\n",
    "        num_layers = [len(x) for x in num_neurons]\n",
    "\n",
    "        f_temp = [x for subl in targets for x in subl]\n",
    "        self.targets_flatten = [x for subl in f_temp for x in subl]\n",
    "        \n",
    "        if len(self.targets_flatten) > 1:\n",
    "            self.PP = True\n",
    "        else:\n",
    "            self.PP = False\n",
    "    \n",
    "\n",
    "        #Build first common block\n",
    "        f_input = Input(shape=(n_feat,))\n",
    "        previous_layer = f_input\n",
    "        for i in range(num_layers[0]):\n",
    "            previous_layer = Dense(num_neurons[0][i],activation=act)(previous_layer)\n",
    "            if self.PP:\n",
    "                previous_layer = BatchNormalization()(previous_layer)\n",
    "        common_out = previous_layer\n",
    "\n",
    "        # build intermediate representations\n",
    "        intermediate_models_out = []\n",
    "        for i in range(len(targets)):\n",
    "            previous_layer = common_out\n",
    "            for j in range(num_layers[1]):\n",
    "                previous_layer = Dense(num_neurons[1][j],activation=act)(previous_layer)\n",
    "                if self.PP:\n",
    "                    previous_layer = BatchNormalization()(previous_layer)\n",
    "            intermediate_models_out.append(previous_layer)\n",
    "\n",
    "        #Build outputs\n",
    "        final_out = []\n",
    "        for group_idx,group in enumerate(targets):\n",
    "            for prop_idx in range(len(group)):\n",
    "                previous_layer = intermediate_models_out[group_idx]\n",
    "                for k in range(num_layers[2]):\n",
    "                    previous_layer = Dense(num_neurons[2][k],activation=act)(previous_layer)\n",
    "                    if self.PP:\n",
    "                        previous_layer = BatchNormalization()(previous_layer)\n",
    "                clayer = previous_layer\n",
    "                temps = []\n",
    "                for pi in range(len(group[prop_idx])):\n",
    "                    previous_layer = clayer\n",
    "                    for li in range(num_layers[3]):\n",
    "                        previous_layer = Dense(num_neurons[3][li])(previous_layer)\n",
    "                    out = Dense(1,activation=self.out_act,name=group[prop_idx][pi])(previous_layer)\n",
    "                    final_out.append(out)\n",
    "\n",
    "        self.model = tf.keras.models.Model(inputs=f_input, outputs=final_out)\n",
    "\n",
    "    def fit(self,data:MODData, val_fraction = 0.0, val_key = None, lr=0.001, epochs = 200, batch_size = 128, xscale='minmax', loss='mse', callbacks=None, verbose=1):\n",
    "        \n",
    "        if self.n_feat > len(data.get_optimal_descriptors()):\n",
    "            raise RuntimeError(\"The model requires more features than computed in data. Please reduce n_feat below or equal to {}\".format(len(data.get_optimal_descriptors())))\n",
    "        self.xscale = xscale\n",
    "        self.target_names = data.names\n",
    "        self.optimal_descriptors = data.get_optimal_descriptors()\n",
    "        x = data.get_featurized_df()[self.optimal_descriptors[:self.n_feat]].values\n",
    "        #print(x.shape)\n",
    "        y = data.get_target_df()[self.targets_flatten].values.transpose()\n",
    "        #print(y.shape)\n",
    "        \n",
    "        #Scale the input features:\n",
    "        if self.xscale == 'minmax':\n",
    "            self.xmin = x.min(axis=0)\n",
    "            self.xmax = x.max(axis=0)\n",
    "            x=(x-self.xmin)/(self.xmax-self.xmin) - 0.5\n",
    "                \n",
    "        elif self.xscale == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "            x = self.scaler.fit_transform(x)\n",
    "\n",
    "        x = np.nan_to_num(x)\n",
    "        \n",
    "        if verbose and self.PP:\n",
    "            if val_fraction>0:\n",
    "                print_callback = LambdaCallback(\n",
    "                  on_epoch_end=lambda epoch,logs: print(\"epoch {}: loss: {:.3f}, val_loss:{:.3f} val_{}:{:.3f}\".format(epoch,logs['loss'],logs['val_loss'],val_key,logs['val_{}_mae'.format(val_key)])))\n",
    "                verbose = 0\n",
    "            else:\n",
    "                print_callback = LambdaCallback(\n",
    "                    on_epoch_end=lambda epoch,logs: print(\"epoch {}: loss: {:.3f}\".format(epoch,logs['loss'])))\n",
    "                verbose = 0\n",
    "            if callbacks is None:\n",
    "                callbacks = [print_callback]\n",
    "            else:\n",
    "                callbacks += [print_callback]\n",
    "\n",
    "        fit_params = {\n",
    "            'x': x,\n",
    "            'y': list(y),\n",
    "            'epochs': epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'verbose': verbose,\n",
    "            'validation_split': val_fraction,\n",
    "            'callbacks': callbacks\n",
    "        }\n",
    "\n",
    "        #print('compile',flush=True)\n",
    "        self.model.compile(loss = loss, optimizer=tf.keras.optimizers.Adam(lr=lr), metrics=['mae'], loss_weights=self.weights)\n",
    "        #print('fit',flush=True)\n",
    "        \n",
    "        history = self.model.fit(**fit_params)\n",
    "\n",
    "        return history\n",
    "\n",
    "\n",
    "    #def fit_preset(self, data:MODData,verbose=0):\n",
    "        \"\"\"\n",
    "        Chooses an optimal hyper-parametered MODNet model from different presets .\n",
    "        The data is first fitted on several well working MODNet presets with a validation set (20% of the furnished data).\n",
    "        The best validating preset is then fitted again on the whole data, and the current model is updated accordingly.\n",
    "        Args:\n",
    "            data: MODData object contain training and validation samples.\n",
    "\n",
    "        Returns: None, object is updated to fit the data.\n",
    "\n",
    "        \"\"\"\n",
    "    #    rlr = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=20, verbose=verbose, mode=\"auto\", min_delta=0)\n",
    "    #    es = EarlyStopping(monitor=\"loss\", min_delta=0.001, patience=300, verbose=verbose, mode=\"auto\", baseline=None,\n",
    "    #                       restore_best_weights=True)\n",
    "    #    callbacks = [rlr,es]\n",
    "    #    val_losses = np.empty((len(MODNET_PRESETS),))\n",
    "    #    for i,params in enumerate(MODNET_PRESETS):\n",
    "    #        logging.info(\"Training preset #{}/{}\".format(i+1,len(MODNET_PRESETS)))\n",
    "    #        n_feat = min(len(data.get_optimal_descriptors()),params['n_feat'])\n",
    "    #        self.model = MODNetModel(self.targets,self.weights,num_neurons=params['num_neurons'],n_feat=n_feat, act=params['act'],out_act=self.out_act).model\n",
    "    #        self.n_feat = n_feat\n",
    "    #        hist = self.fit(data, val_fraction=0.2, lr=params['lr'], epochs=params['epochs'], batch_size=params['batch_size'], loss=params['loss'], callbacks=callbacks, verbose=verbose)\n",
    "    #        val_loss = np.array(hist.history['val_loss'])[-20:].mean()\n",
    "    #        val_losses[i] = val_loss\n",
    "    #        logging.info(\"Validation loss: {:.3f}\".format(val_loss))\n",
    "    #    best_preset = val_losses.argmin()\n",
    "    #    logging.info(\"Preset #{} resulted in lowest validation loss.\\nFitting all data...\".format(best_preset+1))\n",
    "    #    n_feat = min(len(data.get_optimal_descriptors()), MODNET_PRESETS[best_preset]['n_feat'])\n",
    "    #    self.model = MODNetModel(self.targets, self.weights, num_neurons=MODNET_PRESETS[best_preset]['num_neurons'], n_feat=n_feat,\n",
    "    #                             act=MODNET_PRESETS[best_preset]['act'],out_act=self.out_act).model\n",
    "    #    self.n_feat = n_feat\n",
    "    #    self.fit(data, val_fraction=0, lr=MODNET_PRESETS[best_preset]['lr'], epochs=MODNET_PRESETS[best_preset]['epochs'],\n",
    "    #                    batch_size=MODNET_PRESETS[best_preset]['batch_size'], loss=MODNET_PRESETS[best_preset]['loss'], callbacks=callbacks, verbose=verbose)\n",
    "\n",
    "\n",
    "    def predict(self,data):\n",
    "        \n",
    "        x = data.get_featurized_df()[self.optimal_descriptors[:self.n_feat]].values\n",
    "        \n",
    "        #Scale the input features:\n",
    "        if self.xscale == 'minmax':\n",
    "            x=(x-self.xmin)/(self.xmax-self.xmin) - 0.5\n",
    "                \n",
    "        elif self.xscale == 'standard':\n",
    "            x = self.scaler.transform(x)\n",
    "        \n",
    "        x = np.nan_to_num(x)\n",
    "        \n",
    "        if self.PP:\n",
    "            p = np.array(self.model.predict(x))[:,:,0].transpose()\n",
    "        else:\n",
    "            p = np.array(self.model.predict(x))[:,0].transpose()\n",
    "        predictions = pd.DataFrame(p)\n",
    "        predictions.columns = self.targets_flatten\n",
    "        predictions.index = data.structure_ids\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def save(self,filename):\n",
    "        model = self.model\n",
    "        self.model = None\n",
    "        model_json = model.to_json()\n",
    "        fp = open('{}.json'.format(filename), 'w')\n",
    "        fp.write(model_json)\n",
    "        fp.close()\n",
    "        model.save_weights('{}.h5'.format(filename))\n",
    "        fp = open('{}.pkl'.format(filename),'wb')\n",
    "        pickle.dump(self,fp)\n",
    "        fp.close()\n",
    "        self.model = model\n",
    "        print('Saved model')\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        fp = open('{}.pkl'.format(filename),'rb')\n",
    "        mod = pickle.load(fp)\n",
    "        fp.close()\n",
    "        fp = open('{}.json'.format(filename), 'r')\n",
    "        model_json = fp.read()\n",
    "        fp.close()\n",
    "        mod.model = model_from_json(model_json)\n",
    "        mod.model.load_weights('{}.h5'.format(filename))\n",
    "        return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T15:45:40.700023Z",
     "start_time": "2021-02-03T15:45:40.692045Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from modnet.preprocessing import MODData\n",
    "\n",
    "def shuffle_MD(data,random_state=10):\n",
    "    data = copy.deepcopy(data)\n",
    "    ids = data.df_targets.sample(frac=1,random_state=random_state).index\n",
    "    data.df_featurized = data.df_featurized.loc[ids]\n",
    "    data.df_targets = data.df_targets.loc[ids]\n",
    "    data.df_structure = data.df_structure.loc[ids]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def MDKsplit(data,n_splits=5,random_state=10):\n",
    "    data = shuffle_MD(data,random_state=random_state)\n",
    "    ids = np.array(data.structure_ids)\n",
    "    kf = KFold(n_splits=n_splits,shuffle=True,random_state=random_state)\n",
    "    folds = []\n",
    "    for train_idx, val_idx in kf.split(ids):\n",
    "        data_train = MODData(data.df_structure.iloc[train_idx]['structure'].values,data.df_targets.iloc[train_idx].values,target_names=data.df_targets.columns,structure_ids=ids[train_idx])\n",
    "        data_train.df_featurized = data.df_featurized.iloc[train_idx]\n",
    "        #data_train.optimal_features = data.optimal_features\n",
    "        \n",
    "        data_val = MODData(data.df_structure.iloc[val_idx]['structure'].values,data.df_targets.iloc[val_idx].values,target_names=data.df_targets.columns,structure_ids=ids[val_idx])\n",
    "        data_val.df_featurized = data.df_featurized.iloc[val_idx]\n",
    "        #data_val.optimal_features = data.optimal_features\n",
    "\n",
    "        folds.append((data_train,data_val))\n",
    "        \n",
    "    return folds\n",
    "\n",
    "def MD_append(md,lmd):\n",
    "    md = copy.deepcopy(md)\n",
    "    for m in lmd:\n",
    "        md.df_structure.append(m.df_structure)\n",
    "        md.df_targets.append(m.df_targets)\n",
    "        md.df_featurized.append(m.df_featurized)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T15:45:54.571478Z",
     "start_time": "2021-02-03T15:45:40.701733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you use the ChemEnv tool for your research, please consider citing the following reference(s) :\n",
      "==================================================================================================\n",
      "David Waroquiers, Xavier Gonze, Gian-Marco Rignanese, Cathrin Welker-Nieuwoudt, Frank Rosowski,\n",
      "Michael Goebel, Stephan Schenk, Peter Degelmann, Rute Andre, Robert Glaum, and Geoffroy Hautier,\n",
      "\"Statistical analysis of coordination environments in oxides\",\n",
      "Chem. Mater., 2017, 29 (19), pp 8346-8360,\n",
      "DOI: 10.1021/acs.chemmater.7b02766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7455435c10> object, created with modnet version <=0.1.7\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7455435d60> object, created with modnet version <=0.1.7\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7455435910> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7455435f70> object, created with modnet version <=0.1.7\n"
     ]
    }
   ],
   "source": [
    "md_exp = MODData.load('exp_gap_all_mpid')\n",
    "md_exp.df_targets.columns = ['exp_gap','mp_id']\n",
    "md_pbe = MODData.load('pbe_gap.zip')\n",
    "#md_pbe.df_targets.columns = ['gap']\n",
    "md_hse = MODData.load('hse_gap.zip')\n",
    "#md_hse.df_targets.columns = ['gap']\n",
    "md_joint = MODData.load('exp_pbe_joint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T15:45:54.582966Z",
     "start_time": "2021-02-03T15:45:54.573245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmd_joint = copy.deepcopy(md_exp)\\nintersec = set(md_pbe.df_targets.index).intersection(set(md_exp.df_targets['mp_id']))\\nmd_joint.df_targets = md_exp.df_targets.set_index('mp_id').join(md_pbe.df_targets,how='inner').loc[intersec]\\nmd_joint.df_featurized = md_pbe.df_featurized.loc[intersec]\\nmd_joint.df_structure = md_pbe.df_structure.loc[intersec]\\n\\nmd_joint.save('moddatas/exp_pbe_joint')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joint exp and pbe\n",
    "\n",
    "'''\n",
    "\n",
    "df_exp = md_exp.df_targets\n",
    "\n",
    "icsds_n =  [int(x.split('-')[1]) for x in list(df_exp.index)]\n",
    "\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "\n",
    "with MPRester(api_key='DaZc4G3gfZrVogm6') as mpr:\n",
    "    res1 = mpr.query({\"icsd_ids\": {\"$in\": icsds_n}}, properties=[\"material_id\",\"icsd_ids\"],chunk_size=2000)\n",
    "    \n",
    "mapping = {}\n",
    "\n",
    "for el in res1:\n",
    "    for icsd in el['icsd_ids']:\n",
    "        mapping['icsd-'+str(icsd)] = el['material_id']\n",
    "        \n",
    "\n",
    "df_exp['mp_id'] = df_exp.index.map(mapping)\n",
    "\n",
    "md_exp.df_targets = df_exp\n",
    "#md_exp.save('moddatas/exp_gap_all_mpid')\n",
    "'''\n",
    "\n",
    "'''\n",
    "md_joint = copy.deepcopy(md_exp)\n",
    "intersec = set(md_pbe.df_targets.index).intersection(set(md_exp.df_targets['mp_id']))\n",
    "md_joint.df_targets = md_exp.df_targets.set_index('mp_id').join(md_pbe.df_targets,how='inner').loc[intersec]\n",
    "md_joint.df_featurized = md_pbe.df_featurized.loc[intersec]\n",
    "md_joint.df_structure = md_pbe.df_structure.loc[intersec]\n",
    "\n",
    "md_joint.save('moddatas/exp_pbe_joint')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T16:55:59.637848Z",
     "start_time": "2021-02-03T15:51:46.467458Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7416aec6d0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.424\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.397\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.373\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.348\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.385\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.372\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.416\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.361\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.369\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.362\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.366\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.368\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.367\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.357\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.349\n",
      "INFO:root:Preset #4 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           exp_gap   pbe_gap\n",
      "mp-8046   0.061767  0.025327\n",
      "mp-12569  2.260568  0.026822\n",
      "mp-1211  -1.646768  0.025427\n",
      "mp-1723   0.061406  0.025311\n",
      "mp-21149  0.054345  0.028356\n",
      "mae\n",
      "0.4550654079870071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7334633430> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.341\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.308\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.334\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.356\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.309\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.337\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.384\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.348\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.300\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.346\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.368\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.352\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.301\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.320\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.324\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.339\n",
      "INFO:root:Preset #9 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            exp_gap   pbe_gap\n",
      "mp-574273  0.034456  0.017452\n",
      "mp-20905  -0.540270  0.531685\n",
      "mp-28911   3.299709  1.852704\n",
      "mp-22811   0.922594  0.012722\n",
      "mp-1863    0.978782  0.630005\n",
      "mae\n",
      "0.3928549249316345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f73345ce8b0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.323\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.336\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.338\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.369\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.302\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.312\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.319\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.333\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.317\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.305\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.311\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.331\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.287\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.362\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.307\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.372\n",
      "INFO:root:Preset #13 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            exp_gap   pbe_gap\n",
      "mp-2520    0.802592  0.025146\n",
      "mp-541407  0.647221  0.758261\n",
      "mp-14025  -0.051152  0.032541\n",
      "mp-5720   -0.041567  0.018705\n",
      "mp-20581  -0.043653  0.020237\n",
      "mae\n",
      "0.44988406211999166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7334633460> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.349\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.357\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.347\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.358\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.339\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.380\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.365\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.349\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.347\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.359\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.387\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.352\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.330\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.343\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.342\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.325\n",
      "INFO:root:Preset #16 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           exp_gap   pbe_gap\n",
      "mp-20715  0.012959  0.031253\n",
      "mp-15986  0.015188  0.031430\n",
      "mp-10133  0.012715  0.031485\n",
      "mp-2418   1.419075 -0.299332\n",
      "mp-2472   0.220758 -0.774587\n",
      "mae\n",
      "0.40030897566721296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f735c2a29a0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.412\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.384\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.437\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.384\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.376\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.408\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.386\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.384\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.377\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.399\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.357\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.386\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.366\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.389\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.352\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.359\n",
      "INFO:root:Preset #15 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            exp_gap   pbe_gap\n",
      "mp-23222  -0.708200 -0.354188\n",
      "mp-12780  -0.007077 -0.011916\n",
      "mp-2556    0.007094 -0.012063\n",
      "mp-1743   -0.005586 -0.014490\n",
      "mp-866685 -0.007826 -0.010980\n",
      "mae\n",
      "0.3244034972128829\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "random_state = 202010\n",
    "folds = MDKsplit(md_joint,n_splits=k,random_state=random_state)\n",
    "maes = np.ones(5)\n",
    "for i,f in enumerate(folds):\n",
    "    train = f[0]\n",
    "    test = f[1]\n",
    "    fpath = 'train_jointA_{}_{}'.format(random_state,i+1)\n",
    "    if os.path.exists(fpath):\n",
    "        train = MODData.load(fpath)\n",
    "    else:\n",
    "        train.feature_selection(n=-1)\n",
    "        train.save(fpath)\n",
    "    \n",
    "    # assure no overlap\n",
    "    assert len(set(train.df_targets.index).intersection(set(test.df_targets.index))) == 0\n",
    "    \n",
    "    #phase 1\n",
    "    model = MODNetModel([[['pbe_gap'],['exp_gap']]],{'pbe_gap':0.3, 'exp_gap':0.7},act='elu')\n",
    "    model.fit_preset(train,verbose=0)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    true = test.df_targets\n",
    "    error = pred-true\n",
    "    print(error.head())\n",
    "    error = error.drop(pred.index[((pred['exp_gap']).abs()>20)]) # drop unrealistic values: happens extremely rarely\n",
    "    mae = np.abs(error['exp_gap'].values).mean()\n",
    "    print('mae')\n",
    "    print(mae)\n",
    "    maes[i] = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T16:55:59.645846Z",
     "start_time": "2021-02-03T16:55:59.640383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4045033735837458"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp alone: exact same train-test folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T17:38:31.168892Z",
     "start_time": "2021-02-03T16:56:36.920637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f735c2a29a0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss: 0.412\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.425\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.389\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.429\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.403\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.406\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.393\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.358\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.411\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.419\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.400\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.400\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.409\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.419\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.377\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.358\n",
      "INFO:root:Preset #16 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f72a872b4f0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp-8894    -0.206520\n",
      "mp-10289   -0.054868\n",
      "mp-30353   -0.024797\n",
      "mp-20446   -0.022955\n",
      "mp-10910   -0.022781\n",
      "Name: exp_gap, dtype: float32\n",
      "           exp_gap  pbe_gap\n",
      "mp-8046  -0.013438      NaN\n",
      "mp-12569  2.944123      NaN\n",
      "mp-1211  -1.719579      NaN\n",
      "mp-1723  -0.020542      NaN\n",
      "mp-21149  0.009200      NaN\n",
      "mae\n",
      "0.4054699052092022\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss: 0.348\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.330\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.387\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.368\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.340\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.364\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.375\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.316\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.345\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.326\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.381\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.356\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.311\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.367\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.358\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.285\n",
      "INFO:root:Preset #16 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f7416de7fa0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp-8469     -0.334096\n",
      "mp-1916     -0.066629\n",
      "mp-562387   -0.019339\n",
      "mp-10516    -0.012011\n",
      "mp-30650    -0.011654\n",
      "Name: exp_gap, dtype: float32\n",
      "            exp_gap  pbe_gap\n",
      "mp-574273 -0.002374      NaN\n",
      "mp-20905  -1.406700      NaN\n",
      "mp-28911  -3.435160      NaN\n",
      "mp-22811   1.247173      NaN\n",
      "mp-1863    0.143908      NaN\n",
      "mae\n",
      "0.33463067087530834\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss: 0.313\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.356\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.326\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.335\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.336\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.344\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.344\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.344\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.348\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.331\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.339\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.325\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.350\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.364\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.337\n",
      "INFO:root:Preset #1 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f72681859d0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp-4243    -0.009234\n",
      "mp-14025   -0.009234\n",
      "mp-5720    -0.009234\n",
      "mp-20581   -0.009234\n",
      "mp-30060   -0.009234\n",
      "Name: exp_gap, dtype: float32\n",
      "            exp_gap  pbe_gap\n",
      "mp-2520    0.826543      NaN\n",
      "mp-541407  0.445122      NaN\n",
      "mp-14025  -0.009234      NaN\n",
      "mp-5720   -0.009234      NaN\n",
      "mp-20581  -0.009234      NaN\n",
      "mae\n",
      "0.41007692463170886\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss: 0.355\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.380\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.393\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.369\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.358\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.385\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.375\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.352\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.353\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.397\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.356\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.361\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.395\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.352\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.374\n",
      "INFO:root:Preset #15 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7f73344f27c0> object, created with modnet version 0.1.8~develop\n",
      "INFO:root:Training preset #1/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp-30652     0.010638\n",
      "mp-22017     0.010855\n",
      "mp-4288      0.010856\n",
      "mp-28795     0.010870\n",
      "mp-573498    0.010881\n",
      "Name: exp_gap, dtype: float32\n",
      "           exp_gap  pbe_gap\n",
      "mp-20715  0.010932      NaN\n",
      "mp-15986  0.010932      NaN\n",
      "mp-10133  0.010932      NaN\n",
      "mp-2418   1.180664      NaN\n",
      "mp-2472   0.177695      NaN\n",
      "mae\n",
      "0.41450707417526544\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation loss: 0.453\n",
      "INFO:root:Training preset #2/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.458\n",
      "INFO:root:Training preset #3/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.389\n",
      "INFO:root:Training preset #4/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.402\n",
      "INFO:root:Training preset #5/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.373\n",
      "INFO:root:Training preset #6/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.410\n",
      "INFO:root:Training preset #7/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.377\n",
      "INFO:root:Training preset #8/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.367\n",
      "INFO:root:Training preset #9/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.408\n",
      "INFO:root:Training preset #10/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.425\n",
      "INFO:root:Training preset #11/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.371\n",
      "INFO:root:Training preset #12/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.405\n",
      "INFO:root:Training preset #13/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.438\n",
      "INFO:root:Training preset #14/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.401\n",
      "INFO:root:Training preset #15/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.378\n",
      "INFO:root:Training preset #16/16\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n",
      "INFO:root:Validation loss: 0.383\n",
      "INFO:root:Preset #8 resulted in lowest validation loss.\n",
      "Fitting all data...\n",
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp-583234   -0.021648\n",
      "mp-9277     -0.014182\n",
      "mp-10036    -0.012590\n",
      "mp-24650    -0.012590\n",
      "mp-1890     -0.012590\n",
      "Name: exp_gap, dtype: float32\n",
      "            exp_gap  pbe_gap\n",
      "mp-23222  -0.712400      NaN\n",
      "mp-12780  -0.012585      NaN\n",
      "mp-2556    0.664100      NaN\n",
      "mp-1743   -0.012590      NaN\n",
      "mp-866685 -0.012589      NaN\n",
      "mae\n",
      "0.34134119151911535\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "random_state = 202010\n",
    "folds = MDKsplit(md_joint,n_splits=k,random_state=random_state)\n",
    "maes = np.ones(5)\n",
    "for i,f in enumerate(folds):\n",
    "    train = f[0]\n",
    "    test = f[1]\n",
    "    fpath = 'train_jointA_{}_{}'.format(random_state,i+1)\n",
    "    if os.path.exists(fpath):\n",
    "        train = MODData.load(fpath)\n",
    "    else:\n",
    "        temp = copy.deecopy(train.df_targets)\n",
    "        train.df_targets.drop('pbe_gap',axis=1,inplace=True)\n",
    "        train.feature_selection(n=-1)\n",
    "        train.df_targets = temp\n",
    "        train.save(fpath)\n",
    "    \n",
    "    # assure no overlap\n",
    "    print(len(set(train.df_targets.index).intersection(set(test.df_targets.index))))\n",
    "    assert len(set(train.df_targets.index).intersection(set(test.df_targets.index))) == 0\n",
    "    \n",
    "    #phase 1\n",
    "    model = MODNetModel([[['exp_gap']]],{'exp_gap':1},act='elu')\n",
    "    model.model.layers[-1].activation = tf.keras.activations.relu\n",
    "    #print(model.model.summary())\n",
    "    model.fit_preset(train,verbose=0)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    print(pred['exp_gap'].nsmallest(n=5))\n",
    "    true = test.df_targets\n",
    "    error = pred-true\n",
    "    print(error.head())\n",
    "    error = error.drop(pred.index[((pred['exp_gap']).abs()>20)]) # drop unrealistic values: happens extremely rarely\n",
    "    mae = np.abs(error['exp_gap'].values).mean()\n",
    "    print('mae')\n",
    "    print(mae)\n",
    "    maes[i] = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T17:38:31.176552Z",
     "start_time": "2021-02-03T17:38:31.171751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38120515328212"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modnet]",
   "language": "python",
   "name": "conda-env-modnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
